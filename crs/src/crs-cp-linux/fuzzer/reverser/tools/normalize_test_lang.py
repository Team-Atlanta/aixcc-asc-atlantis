from typing import Dict
from copy import copy
from .sample import sample1, sample2, sample3, sample4, sample5, sample15, sample16, sample17, sample18
from .test_lang import TestLang, Record, Field, parse_test_lang 
from .tokens import NORMAL_DATA_ATTRS, INPUT
from .hash_equivalence import hash_record

class nondata_field_remover:   
    def remove_nondata_attrs_from_field(field: Field) -> Field:
        nfield_name = field.name
        nfield_type = field.type
        nfield_attrs = {}
        if field.type == Field.Normal:
            for key, value in field.attrs.items():
                if key in NORMAL_DATA_ATTRS:
                    nfield_attrs[key] = value
        else:
            for key, value in field.attrs.items():
                nfield_attrs[key] = value
        nfield = Field(nfield_name, nfield_type, nfield_attrs)
        return nfield
    
    def remove_nondata_attrs_from_record(record: Record) -> Record:
        nrecord = Record()
        nrecord.name = record.name
        for field in record.fields:
            nfield = nondata_field_remover.remove_nondata_attrs_from_field(field)
            nrecord.add_field(nfield)
        return nrecord


    def remove_nondata_attrs_from_testlang(test_lang: TestLang) -> TestLang:
        ntest_lang = TestLang()
        for record_name, record in test_lang.records.items():
            nrecord = nondata_field_remover.remove_nondata_attrs_from_record(record)
            ntest_lang.add_record(nrecord)
        return ntest_lang
    

class normalizer:
    def __init__(self, obj: TestLang | Record | Field | None = None, mapping=None, counter=0):
        self.input = obj
        self.counter = counter
        if not mapping:
            mapping = {}
        self.mapping = mapping
        self.reverse_mapping = {}

    def add_mapping(self, key: str, value: str) -> str:
        if key not in self.mapping.keys():
            self.mapping[key] = value
            self.reverse_mapping[value] = key
            return value
        else:
            # This should have been caught by the handler
            raise ValueError("Key already exists", key)
        
    def handle_mapping(self, key) -> str:
        if key in self.mapping.keys():
            return self.mapping[key]
        else:
            new_key = self.add_mapping(key, 'v' + str(self.counter))
            self.counter += 1
            return new_key

    def normalize_field(self, field: Field) -> Field:
        nfield_name = self.handle_mapping(field.name)
        nfield_type = field.type
        nfield_attrs = {}
        # nfield_attrs: Dict[str, str]
        for key, value in field.attrs.items():
            if value in self.mapping.keys():
                nfield_attrs[key] = self.mapping[value]
            else:
                nfield_attrs[key] = value
        nfield = Field(nfield_name, nfield_type, nfield_attrs)
        return nfield

    def normalize_record(self, record: Record) -> Record:
        nrecord = Record()
        if record.name != INPUT:
            nrecord.name = self.handle_mapping(record.name)
        else:
            nrecord.name = record.name
        nrecord.type = record.type
        for field in record.fields:
            nfield = self.normalize_field(field)
            nrecord.add_field(nfield)
        # sort union fields so string comparison passes
        if nrecord.type == Record.UNION:
            nrecord.fields.sort(key=lambda field: field.name)
        return nrecord

    # Assume that test_lang is already unwrapped
    def normalize_test_lang(self, test_lang: TestLang) -> TestLang:
        ntest_lang = TestLang()
        # Use hashes to 'sort' the records. A hash binds to a record's structure
        record_hashes = sorted([ (name, hash_record(record, test_lang.records, False))
                                 for name, record in test_lang.records.items() ],
                               key=lambda t: t[1])
        
        # Do a pass so that record names are stored in TL's mapping
        for record_name, _ in record_hashes:
            if record_name != INPUT:
                self.handle_mapping(record_name)
        # TODO do a DFS normalization traversal for allowing parental scoping assuming tree?
        # Now normalize all records, starting from the first non-record counter name
        for record_name, _ in record_hashes:
            record = test_lang.records[record_name]
            # We want to 'forget' the local names generated by each record
            record_normalizer = normalizer(record, mapping=copy(self.mapping), counter=self.counter)
            nrecord = record_normalizer()
            # Uncomment below if we need globally unique names for Normal Fields
            # self.counter = record_normalizer.counter
            ntest_lang.add_record(nrecord)
        return ntest_lang
    
    def __call__(self) -> TestLang | Record | Field:
        if isinstance(self.input, TestLang):
            return self.normalize_test_lang(self.input)
        elif isinstance(self.input, Record):
            return self.normalize_record(self.input)
        elif isinstance(self.input, Field):
            return self.normalize_field(self.input)
        else:
            raise ValueError("Invalid object type")


def normalize_and_compare_test_lang(tl1: TestLang, tl2: TestLang, debug = False) -> bool:
    ntl1 = normalizer(tl1)()
    ntl2 = normalizer(tl2)()
    if debug:
        print(ntl1)
        print(ntl2)
    return ntl1 == ntl2

def test_basic_normalization():
    tl1 = parse_test_lang(sample1)
    tl2 = parse_test_lang(sample2)
    tl3 = parse_test_lang(sample3)
    tl15 = parse_test_lang(sample15)
    tl16 = parse_test_lang(sample16)
    tl17 = parse_test_lang(sample17)
    tl18 = parse_test_lang(sample18)

    ntl1 = normalizer(tl1)()
    ntl2 = normalizer(tl2)()
    ntl3 = normalizer(tl3)()
    ntl15 = normalizer(tl15)()
    ntl16 = normalizer(tl16)()
    ntl17 = normalizer(tl17)()
    ntl18 = normalizer(tl18)()

    print("Normalized sample1:\n", ntl1, sep="")
    print("Normalized sample2:\n", ntl2, sep="")
    print("Normalized sample3:\n", ntl3, sep="")
    print("Normalized sample15:\n", ntl15, sep="")
    print("Normalized sample16:\n", ntl16, sep="")
    print("Normalized sample17:\n", ntl17, sep="")
    print("Normalized sample18:\n", ntl18, sep="")

    if normalize_and_compare_test_lang(tl1, tl2):
        print("sample1 ≡ sample2")
    else:
        print("sample1 !≡ sample2")

    if normalize_and_compare_test_lang(tl2, tl3):
        print("sample2 ≡ sample3")
    else:
        print("sample2 !≡ sample3")

    if normalize_and_compare_test_lang(tl3, tl15):
        print("sample3 ≡ sample15")
    else:
        print("sample3 !≡ sample15")

    if normalize_and_compare_test_lang(tl16, tl15):
        print("sample16 ≡ sample15")
    else:
        print("sample16 !≡ sample15")

    if normalize_and_compare_test_lang(tl17, tl18):
        print("sample17 ≡ sample18")
    else:
        print("sample17 !≡ sample18")

def test_stripped_attribute_normalization():
    tl4 = parse_test_lang(sample4)
    tl5 = parse_test_lang(sample5)
    stl4 = nondata_field_remover.remove_nondata_attrs_from_testlang(tl4)
    stl5 = nondata_field_remover.remove_nondata_attrs_from_testlang(tl5)
    
    print("Stripped sample4:\n", stl4, sep="")
    print("Stripped sample5:\n", stl5, sep="")

    if normalize_and_compare_test_lang(stl4, stl5):
        print("sample4 ≡ sample5")
    else:
        print("sample4 !≡ sample5")

if __name__ == "__main__":
    test_basic_normalization()
    test_stripped_attribute_normalization()
