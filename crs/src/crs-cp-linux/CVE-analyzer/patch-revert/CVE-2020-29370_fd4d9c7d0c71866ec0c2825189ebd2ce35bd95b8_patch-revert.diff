diff --git a/mm/slub.c b/mm/slub.c
index eae5bb47b22f..17dc00e33115 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -3174,15 +3174,6 @@ int kmem_cache_alloc_bulk(struct kmem_cache *s, gfp_t flags, size_t size,
 		void *object = c->freelist;
 
 		if (unlikely(!object)) {
-			/*
-			 * We may have removed an object from c->freelist using
-			 * the fastpath in the previous iteration; in that case,
-			 * c->tid has not been bumped yet.
-			 * Since ___slab_alloc() may reenable interrupts while
-			 * allocating memory, we should bump c->tid now.
-			 */
-			c->tid = next_tid(c->tid);
-
 			/*
 			 * Invoking slow path likely have side-effect
 			 * of re-populating per CPU c->freelist
